import os, json, glob
import multiprocessing as mp
from dotenv import load_dotenv
import openai
from typing import Dict, List, Set
from util import merge_json, parse_json

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ëŒ€í­ í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ - ë” ë§ì€ ê´€ê³„ íƒ€ì…ê³¼ íŒ¨í„´ ì§€ì›
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OUTPUT_ROOT = os.getenv("OUTPUT_ROOT", "output")
SCHEMA_DIR = os.path.join(OUTPUT_ROOT, "schema")
CHUNKS_DIR = os.path.join(OUTPUT_ROOT, "chunked_document")
os.makedirs(SCHEMA_DIR, exist_ok=True)

# í™•ì¥ëœ ë‰´ìŠ¤ ë„ë©”ì¸ ìŠ¤í‚¤ë§ˆ í…œí”Œë¦¿ (PDF ì œì•ˆì‚¬í•­ ë°˜ì˜)
ENHANCED_NEWS_DOMAIN_SCHEMA = {
    "nodes": [
        {"label": "PERSON", "name": "String", "properties": {"full_name": "string", "role": "string", "nationality": "string", "age": "string"}},
        {"label": "COMPANY", "name": "String", "properties": {"full_name": "string", "industry": "string", "headquarters": "string", "founded": "string", "ceo": "string"}},
        {"label": "ORGANIZATION", "name": "String", "properties": {"type": "string", "description": "string", "headquarters": "string"}},
        {"label": "LOCATION", "name": "String", "properties": {"type": "string", "country": "string", "region": "string"}},
        {"label": "EVENT", "name": "String", "properties": {"date": "string", "type": "string", "description": "string", "location": "string"}},
        {"label": "PRODUCT", "name": "String", "properties": {"category": "string", "description": "string", "launch_date": "string", "company": "string"}},
        {"label": "TECHNOLOGY", "name": "String", "properties": {"category": "string", "description": "string", "field": "string"}},
        {"label": "PROJECT", "name": "String", "properties": {"description": "string", "start_date": "string", "status": "string"}},
        {"label": "INVESTMENT", "name": "String", "properties": {"amount": "string", "date": "string", "type": "string"}},
        {"label": "AGREEMENT", "name": "String", "properties": {"type": "string", "date": "string", "description": "string"}}
    ],
    "relations": [
        # ê³ ìš© ê´€ê³„
        {"start_node": "PERSON", "relationship": "WORKS_FOR", "end_node": "COMPANY", "properties": {"position": "string", "since": "string"}},
        {"start_node": "PERSON", "relationship": "CEO_OF", "end_node": "COMPANY", "properties": {"since": "string"}},
        {"start_node": "PERSON", "relationship": "FOUNDER_OF", "end_node": "COMPANY", "properties": {"date": "string"}},
        {"start_node": "PERSON", "relationship": "BOARD_MEMBER_OF", "end_node": "COMPANY", "properties": {"role": "string"}},
        
        # ìœ„ì¹˜ ê´€ê³„
        {"start_node": "COMPANY", "relationship": "HEADQUARTERED_IN", "end_node": "LOCATION", "properties": {}},
        {"start_node": "COMPANY", "relationship": "LOCATED_IN", "end_node": "LOCATION", "properties": {}},
        {"start_node": "EVENT", "relationship": "HELD_IN", "end_node": "LOCATION", "properties": {}},
        {"start_node": "PERSON", "relationship": "LIVES_IN", "end_node": "LOCATION", "properties": {}},
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ê³„
        {"start_node": "COMPANY", "relationship": "ACQUIRED", "end_node": "COMPANY", "properties": {"date": "string", "amount": "string"}},
        {"start_node": "COMPANY", "relationship": "PARTNERED_WITH", "end_node": "COMPANY", "properties": {"type": "string", "date": "string"}},
        {"start_node": "COMPANY", "relationship": "INVESTED_IN", "end_node": "COMPANY", "properties": {"amount": "string", "date": "string"}},
        {"start_node": "COMPANY", "relationship": "COMPETES_WITH", "end_node": "COMPANY", "properties": {"market": "string"}},
        {"start_node": "COMPANY", "relationship": "SUBSIDIARY_OF", "end_node": "COMPANY", "properties": {}},
        
        # ì œí’ˆ/ê¸°ìˆ  ê´€ê³„
        {"start_node": "COMPANY", "relationship": "PRODUCES", "end_node": "PRODUCT", "properties": {}},
        {"start_node": "COMPANY", "relationship": "DEVELOPS", "end_node": "TECHNOLOGY", "properties": {}},
        {"start_node": "PERSON", "relationship": "INVENTED", "end_node": "TECHNOLOGY", "properties": {"date": "string"}},
        {"start_node": "PRODUCT", "relationship": "USES", "end_node": "TECHNOLOGY", "properties": {}},
        
        # ì´ë²¤íŠ¸ ê´€ê³„
        {"start_node": "PERSON", "relationship": "PARTICIPATED_IN", "end_node": "EVENT", "properties": {"role": "string"}},
        {"start_node": "COMPANY", "relationship": "SPONSORED", "end_node": "EVENT", "properties": {}},
        {"start_node": "PERSON", "relationship": "ATTENDED", "end_node": "EVENT", "properties": {}},
        {"start_node": "PERSON", "relationship": "SPOKE_AT", "end_node": "EVENT", "properties": {"topic": "string"}},
        
        # í”„ë¡œì íŠ¸ ê´€ê³„
        {"start_node": "COMPANY", "relationship": "LEADS", "end_node": "PROJECT", "properties": {}},
        {"start_node": "PERSON", "relationship": "MANAGES", "end_node": "PROJECT", "properties": {}},
        {"start_node": "COMPANY", "relationship": "COLLABORATES_ON", "end_node": "PROJECT", "properties": {}},
        
        # ë°©ë¬¸/ë§Œë‚¨ ê´€ê³„
        {"start_node": "PERSON", "relationship": "VISITED", "end_node": "COMPANY", "properties": {"date": "string", "purpose": "string"}},
        {"start_node": "PERSON", "relationship": "MET_WITH", "end_node": "PERSON", "properties": {"date": "string", "purpose": "string"}},
        
        # íˆ¬ì ê´€ê³„
        {"start_node": "COMPANY", "relationship": "RECEIVED_INVESTMENT", "end_node": "INVESTMENT", "properties": {}},
        {"start_node": "PERSON", "relationship": "MADE_INVESTMENT", "end_node": "INVESTMENT", "properties": {}},
        
        # ê³„ì•½/í˜‘ì • ê´€ê³„
        {"start_node": "COMPANY", "relationship": "SIGNED", "end_node": "AGREEMENT", "properties": {}},
        {"start_node": "PERSON", "relationship": "NEGOTIATED", "end_node": "AGREEMENT", "properties": {}}
    ]
}

# í•œêµ­ì–´ ê´€ê³„ í‘œí˜„ ë§¤í•‘ (PDF ì œì•ˆì‚¬í•­)
KOREAN_RELATION_PATTERNS = {
    "WORKS_FOR": ["ì¼í•˜ë‹¤", "ê·¼ë¬´í•˜ë‹¤", "ê³ ìš©ë˜ë‹¤", "ì¬ì§í•˜ë‹¤", "ì†Œì†ë˜ë‹¤", "ë‹¤ë‹ˆë‹¤"],
    "CEO_OF": ["ëŒ€í‘œì´ì‚¬", "ìµœê³ ê²½ì˜ì", "CEO", "ì‚¬ì¥", "ëŒ€í‘œ"],
    "FOUNDER_OF": ["ì°½ë¦½í•˜ë‹¤", "ì°½ì—…í•˜ë‹¤", "ì„¤ë¦½í•˜ë‹¤", "ì°½ì„¤í•˜ë‹¤"],
    "HEADQUARTERED_IN": ["ë³¸ì‚¬", "ë³¸ë¶€", "ì‚¬ì˜¥", "ë³¸ì "],
    "LOCATED_IN": ["ìœ„ì¹˜í•˜ë‹¤", "ìë¦¬í•˜ë‹¤", "ìˆë‹¤"],
    "ACQUIRED": ["ì¸ìˆ˜í•˜ë‹¤", "ë§¤ì…í•˜ë‹¤", "ì‚¬ë“¤ì´ë‹¤", "ì¸ìˆ˜í•©ë³‘"],
    "PARTNERED_WITH": ["í˜‘ë ¥í•˜ë‹¤", "íŒŒíŠ¸ë„ˆì‹­", "ì œíœ´í•˜ë‹¤", "í˜‘ì—…í•˜ë‹¤"],
    "INVESTED_IN": ["íˆ¬ìí•˜ë‹¤", "ì¶œìí•˜ë‹¤", "ìê¸ˆì¡°ë‹¬"],
    "VISITED": ["ë°©ë¬¸í•˜ë‹¤", "ì°¾ì•„ê°€ë‹¤", "ë“¤ë¥´ë‹¤"],
    "MET_WITH": ["ë§Œë‚˜ë‹¤", "ë©´ë‹´í•˜ë‹¤", "íšŒë™í•˜ë‹¤", "ë¯¸íŒ…"],
    "PARTICIPATED_IN": ["ì°¸ê°€í•˜ë‹¤", "ì°¸ì—¬í•˜ë‹¤", "ì¶œì„í•˜ë‹¤"],
    "ATTENDED": ["ì°¸ì„í•˜ë‹¤", "ì¶œì„í•˜ë‹¤", "ì°¸ê´€í•˜ë‹¤"],
    "SPOKE_AT": ["ë°œí‘œí•˜ë‹¤", "ì—°ì„¤í•˜ë‹¤", "ê°•ì—°í•˜ë‹¤", "ê¸°ì¡°ì—°ì„¤"]
}

ENHANCED_SYSTEM_MSG = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ í¬ê´„ì ì¸ ì§€ì‹ ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ì–‘í•œ ê´€ê³„ íƒ€ì…ì„ ì¸ì‹í•˜ê³  í•œêµ­ì–´ í‘œí˜„ì„ í‘œì¤€ ê´€ê³„ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.
ë¹„ì¦ˆë‹ˆìŠ¤, ê¸°ìˆ , ì •ì¹˜, ì‚¬íšŒ ê´€ê³„ë¥¼ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

def _enhanced_process_chunk(args: tuple[int, str, str]) -> dict:
    """í–¥ìƒëœ ì²­í¬ë³„ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ - í™•ì¥ëœ ê´€ê³„ íƒ€ì… ì§€ì›"""
    idx, purpose, system = args
    
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    client = openai.OpenAI(api_key=api_key)
    
    fname = f"{CHUNKS_DIR}/chunked_output_{idx}.txt"
    with open(fname, "r", encoding="utf-8") as f:
        content = f.read()
    
    # ê´€ê³„ íŒ¨í„´ ê°€ì´ë“œ ìƒì„±
    relation_guide = ""
    for rel_type, korean_patterns in KOREAN_RELATION_PATTERNS.items():
        relation_guide += f"- {rel_type}: {', '.join(korean_patterns)}\n"
    
    prompt = f"""ì£¼ì–´ì§„ í•œêµ­ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ í…ìŠ¤íŠ¸ì—ì„œ **'{purpose}'** ëª©ì ì˜ í™•ì¥ëœ ì§€ì‹ ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

### í™•ì¥ëœ ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ (ì°¸ê³  ë° í™•ì¥):
{json.dumps(ENHANCED_NEWS_DOMAIN_SCHEMA, ensure_ascii=False, indent=2)}

### í•œêµ­ì–´ ê´€ê³„ í‘œí˜„ ê°€ì´ë“œ:
{relation_guide}

### ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ì›ì¹™:
1. **í¬ê´„ì  ê´€ê³„**: ë‹¨ìˆœí•œ WORKS_FORë¥¼ ë„˜ì–´ CEO_OF, FOUNDER_OF, BOARD_MEMBER_OF ë“± êµ¬ì²´ì  ê´€ê³„
2. **ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ê³„**: ACQUIRED, PARTNERED_WITH, INVESTED_IN, COMPETES_WITH, SUBSIDIARY_OF
3. **ì´ë²¤íŠ¸ ê´€ê³„**: PARTICIPATED_IN, ATTENDED, SPOKE_AT, SPONSORED
4. **ìœ„ì¹˜ ê´€ê³„**: HEADQUARTERED_IN (ë³¸ì‚¬), LOCATED_IN (ì¼ë°˜), HELD_IN (ì´ë²¤íŠ¸)
5. **í”„ë¡œì íŠ¸ ê´€ê³„**: LEADS, MANAGES, COLLABORATES_ON

### í™•ì¥ ì§€ì¹¨:
- í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬ë˜ëŠ” ìƒˆë¡œìš´ ê´€ê³„ íŒ¨í„´ì„ ì¶”ê°€í•˜ì„¸ìš”
- í•œêµ­ì–´ í‘œí˜„ì„ ì˜ì–´ í‘œì¤€ ê´€ê³„ëª…ìœ¼ë¡œ ë§¤í•‘í•˜ì„¸ìš”
- ì‹œê°„, ê¸ˆì•¡, ìœ„ì¹˜ ë“± ê´€ê³„ì˜ ì†ì„±(properties)ì„ í¬í•¨í•˜ì„¸ìš”
- ì•”ì‹œì  ê´€ê³„ë„ ëª…ì‹œì ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆì— í¬í•¨í•˜ì„¸ìš”

### ì˜ˆì‹œ:
- "ì‚¼ì„±ì „ìë¥¼ ì°½ì—…í•œ ì´ë³‘ì² " â†’ FOUNDER_OF ê´€ê³„ í•„ìš”
- "êµ¬ê¸€ê³¼ íŒŒíŠ¸ë„ˆì‹­ ì²´ê²°" â†’ PARTNERED_WITH ê´€ê³„ í•„ìš”
- "AI ì»¨í¼ëŸ°ìŠ¤ì—ì„œ ê¸°ì¡°ì—°ì„¤" â†’ SPOKE_AT ê´€ê³„ í•„ìš”

### í…ìŠ¤íŠ¸:
{content}

### í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ (JSON):"""

    resp = client.chat.completions.create(
        model="gpt-4o",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2
    )
    
    parsed = parse_json(resp.choices[0].message.content)
    
    # ê°œë³„ ê²°ê³¼ ì €ì¥
    out_path = os.path.join(SCHEMA_DIR, f"schema_{idx}.json")
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(parsed, f, ensure_ascii=False, indent=2)
    
    print(f"[{idx}] í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ ì™„ë£Œ")
    return parsed

def validate_and_refine_enhanced_schema(merged_schema: Dict) -> Dict:
    """í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° ì •ì œ"""
    load_dotenv()
    api_key = os.getenv("OPENAI_API_KEY")
    client = openai.OpenAI(api_key=api_key)
    
    # í•œêµ­ì–´ ê´€ê³„ ë§¤í•‘ ì •ë³´ ì œê³µ
    korean_mapping_info = json.dumps(KOREAN_RELATION_PATTERNS, ensure_ascii=False, indent=2)
    
    prompt = f"""ë‹¤ìŒì€ í•œêµ­ì–´ ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì¶”ì¶œí•œ í™•ì¥ëœ ìŠ¤í‚¤ë§ˆì…ë‹ˆë‹¤. 
ì´ë¥¼ ê²€í† í•˜ê³  ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ì •ì œí•˜ê³  í‘œì¤€í™”í•˜ì„¸ìš”:

### ì •ì œ ê¸°ì¤€:
1. **ê´€ê³„ í†µí•©**: ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ê´€ê³„ë¥¼ í‘œì¤€ëª…ìœ¼ë¡œ í†µì¼
   - EMPLOYED_BY, WORKS_AT â†’ WORKS_FOR
   - HEADQUARTERED_IN, BASED_IN â†’ HEADQUARTERED_IN (ë³¸ì‚¬ì˜ ê²½ìš°)
   - COLLABORATED_WITH â†’ PARTNERED_WITH

2. **í•œêµ­ì–´ ë§¤í•‘**: í•œêµ­ì–´ ê´€ê³„ í‘œí˜„ì„ í‘œì¤€ ì˜ì–´ëª…ìœ¼ë¡œ ë³€í™˜
{korean_mapping_info}

3. **ê´€ê³„ ê³„ì¸µí™”**: ë” êµ¬ì²´ì ì¸ ê´€ê³„ë¥¼ ìš°ì„ 
   - CEO_OFëŠ” WORKS_FORë³´ë‹¤ êµ¬ì²´ì 
   - FOUNDER_OFëŠ” ì¼ë°˜ì  ì†Œì†ë³´ë‹¤ êµ¬ì²´ì 

4. **ì†ì„± í‘œì¤€í™”**: ë‚ ì§œ, ê¸ˆì•¡, ìœ„ì¹˜ ë“± ì¼ê´€ëœ í˜•ì‹
   - date â†’ "YYYY-MM-DD" ë˜ëŠ” "YYYY" í˜•ì‹
   - amount â†’ ìˆ«ìì™€ ë‹¨ìœ„ í‘œì¤€í™”

5. **ì¤‘ë³µ ì œê±°**: ì˜ë¯¸ìƒ ë™ì¼í•œ ë…¸ë“œ/ê´€ê³„ ì œê±°

### í˜„ì¬ ìŠ¤í‚¤ë§ˆ:
{json.dumps(merged_schema, ensure_ascii=False, indent=2)}

### ì •ì œëœ í™•ì¥ ìŠ¤í‚¤ë§ˆ (JSON):"""

    resp = client.chat.completions.create(
        model="gpt-4o",
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": "ìŠ¤í‚¤ë§ˆ ì •ì œ ë° í‘œì¤€í™” ì „ë¬¸ê°€ë¡œì„œ í¬ê´„ì ì´ê³  ì¼ê´€ëœ ìŠ¤í‚¤ë§ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1
    )
    
    return parse_json(resp.choices[0].message.content)

def extract_enhanced_schema_mp(max_workers: int = 4, purpose: str = "ì¢…í•© ë‰´ìŠ¤ ë¶„ì„"):
    """í™•ì¥ëœ ë©€í‹°í”„ë¡œì„¸ì‹± ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ"""
    files = sorted(glob.glob(os.path.join(CHUNKS_DIR, "chunked_output_*.txt")))
    if not files:
        print("âš ï¸ chunked_document í´ë”ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    indices = [int(os.path.splitext(os.path.basename(f))[0].split("_")[-1]) for f in files]
    
    # 1ë‹¨ê³„: ë³‘ë ¬ ì¶”ì¶œ
    print(f"ğŸš€ 1ë‹¨ê³„: í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ (workers={max_workers}, ì´ {len(indices)}ê°œ)")
    with mp.Pool(processes=max_workers) as pool:
        all_schemas = pool.map(_enhanced_process_chunk, [(i, purpose, ENHANCED_SYSTEM_MSG) for i in indices])
    
    # ë³‘í•© (í™•ì¥ëœ ê¸°ë³¸ ìŠ¤í‚¤ë§ˆì—ì„œ ì‹œì‘)
    merged = ENHANCED_NEWS_DOMAIN_SCHEMA.copy()
    for sc in all_schemas:
        merged = merge_json(merged, sc, node_key=("label",))
    
    # ì¤‘ê°„ ì €ì¥
    temp_path = os.path.join(SCHEMA_DIR, "schema_merged_enhanced.json")
    with open(temp_path, "w", encoding="utf-8") as f:
        json.dump(merged, f, ensure_ascii=False, indent=2)
    
    # 2ë‹¨ê³„: ê²€ì¦ ë° ì •ì œ
    print("ğŸ” 2ë‹¨ê³„: í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ê²€ì¦ ë° ì •ì œ")
    refined = validate_and_refine_enhanced_schema(merged)
    
    # ìµœì¢… ì €ì¥
    final_path = os.path.join(SCHEMA_DIR, "schema.json")
    with open(final_path, "w", encoding="utf-8") as f:
        json.dump(refined, f, ensure_ascii=False, indent=2)
    
    # í†µê³„ ì¶œë ¥
    node_count = len(refined.get('nodes', []))
    relation_count = len(refined.get('relations', []))
    
    print(f"âœ… í™•ì¥ëœ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ ì™„ë£Œ â†’ {final_path}")
    print(f"ğŸ“Š í™•ì¥ëœ ë…¸ë“œ íƒ€ì…: {node_count}ê°œ")
    print(f"ğŸ“Š í™•ì¥ëœ ê´€ê³„ íƒ€ì…: {relation_count}ê°œ")
    
    # ê´€ê³„ íƒ€ì…ë³„ ë¶„ë¥˜ ì¶œë ¥
    relation_types = [rel['relationship'] for rel in refined.get('relations', [])]
    from collections import Counter
    relation_stats = Counter(relation_types)
    
    print("ğŸ“ˆ ê´€ê³„ íƒ€ì… ë¶„í¬:")
    for rel_type, count in relation_stats.most_common(10):
        print(f"   {rel_type}: {count}")

def main(purpose="ì¢…í•© ë‰´ìŠ¤ ë¶„ì„"):
    extract_enhanced_schema_mp(max_workers=min(4, os.cpu_count() or 2), purpose=purpose)

if __name__ == "__main__":
    main()