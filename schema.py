import os
import json
import openai
from dotenv import load_dotenv

from util import merge_json, parse_json

schema_dir = "./output/schema"
os.makedirs(schema_dir, exist_ok=True)

chunks_dir = "./output/chunked_document"


load_dotenv()   
api_key = os.getenv("OPENAI_API_KEY")

client = openai.OpenAI(api_key=api_key)

purpose = input('ëª©ì  ì…ë ¥: ')

system_msg = (
    "You extract entity/relation schemas from text for knowledge graphs used in RAG systems. "
    "Respond with valid JSON only."
)

from collections import defaultdict



i = 0
while True:
    filename = f"{chunks_dir}/chunked_output_{i}.txt"
    
    if not os.path.exists(filename):
        print(f"ğŸ“ íŒŒì¼ ì—†ìŒ: {filename} â†’ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

    with open(filename, "r", encoding="utf-8") as f:
        content = f.read()

    # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = content + '''\n\nGive me Json Schema of Node types and Relations types 
            to make a knowledge graph for RAG system "'''+purpose+'''", 
            using this text, in the form of  
            {
                "nodes": [{"label": "NODE_LABEL", "name": String, "properties": {} }],  
                "relations": [{"start_node": NodeLabel, "relationship": "RELATION_NAME", "end_node": NodeLabel, "properties":{} }]
            }.  
            You just have to decide keys of properties and for each property key you should put its data type as value.
            For relations, you should treat Node Labels as type.
            '''
    # OpenAI GPT í˜¸ì¶œ
    response = client.chat.completions.create(
        model="o1",
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": prompt}
        ]
    )


    # ì‘ë‹µ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
    gpt_output = response.choices[0].message.content
    parsed_json = parse_json(gpt_output)
    schema_path = schema_dir+'/schema.json'
    
    with open(schema_path+f'_{i}.json', "w", encoding="utf-8") as f:
        json.dump(parsed_json, f, ensure_ascii=False, indent=4)

    if not os.path.exists(schema_path):
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± + parsed_json ì €ì¥
        with open(schema_path, "w", encoding="utf-8") as f:
            json.dump(parsed_json, f, ensure_ascii=False, indent=4)
        print("âœ… schema.jsonì´ ì—†ì–´ì„œ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        old_schema = None
    else:
        # íŒŒì¼ì´ ìˆìœ¼ë©´ ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
        with open(schema_path, "r", encoding="utf-8") as f:
            old_schema = json.load(f)
        print("ğŸ“„ ê¸°ì¡´ schema.jsonì„ old_schemaë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        merged_schema = merge_json(old_schema, parsed_json, node_key=("label",))
        with open(schema_path, "w", encoding="utf-8") as f:
            json.dump(merged_schema, f, ensure_ascii=False, indent=4)
        print("âœ… ë³‘í•©ëœ schema ì €ì¥ ì™„ë£Œ: schema.json")

    

    
    i += 1

